{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06482b9",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. \n",
    "\n",
    "Imagine that we want to compete on Jeopardy, and we're looking for any way to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help us win.\n",
    "\n",
    "## Jeopardy Questions\n",
    "\n",
    "The dataset is named `jeopardy.csv`, and contains `20000` rows from the beginning of a full dataset of Jeopardy questions, which we can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file). Here's the beginning of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acec7306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216930, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print(jeopardy.shape)\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b76e57",
   "metadata": {},
   "source": [
    "As we can see, each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "- `Show Number` - the Jeopardy episode number\n",
    "\n",
    "\n",
    "- `Air Date` - the date the episode aired\n",
    "\n",
    "\n",
    "- `Round` - the round of Jeopardy\n",
    "\n",
    "\n",
    "- `Category` - the category of the question\n",
    "\n",
    "\n",
    "- `Value` - the number of dollars the correct answer is worth\n",
    "\n",
    "\n",
    "- `Question` - the text of the question\n",
    "\n",
    "\n",
    "- `Answer` - the text of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41898c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24b6cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Removing spaces from column names\n",
    "jeopardy.columns = [name.strip() for name in jeopardy.columns]\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe00df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Show Number  216930 non-null  int64 \n",
      " 1   Air Date     216930 non-null  object\n",
      " 2   Round        216930 non-null  object\n",
      " 3   Category     216930 non-null  object\n",
      " 4   Value        216930 non-null  object\n",
      " 5   Question     216930 non-null  object\n",
      " 6   Answer       216928 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4871cc1",
   "metadata": {},
   "source": [
    "We can change type of some columns to appropriate ones - e.g. date and int.\n",
    "\n",
    "## Normalizing Text\n",
    "\n",
    "Before we can start doing analysis on the Jeopardy questions, we need to normalize all of the text columns (the `Question` and `Answer` columns). The idea of normalization is to ensure that we put words in lowercase and remove punctuation so `Don't` and `don't` aren't considered to be different words when we compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385d553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "### Convert string to lowercase and remove all punctuation\n",
    "def normalize_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e40ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize Question and Answer columns\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213102c",
   "metadata": {},
   "source": [
    "## Normalizing Columns\n",
    "\n",
    "Now that we've normalized the text columns, there are also some other columns to normalize.\n",
    "\n",
    "The `Value` column should be numeric, to allow us to manipulate it easier. We'll need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "The `Air Date` column should also be a datetime instead of a string, to enable us to work it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "223f2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove punctuation and convert to int\n",
    "def normalize_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "165081fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize values\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b1b7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format datetime\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea05f9",
   "metadata": {},
   "source": [
    "## Answers in Questions\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question\n",
    "- How often questions are repeated\n",
    "\n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We'll work on the first question and come back to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19dc3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count relative matches of answers in questions\n",
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "738dd6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05792070323661354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)\n",
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf0678",
   "metadata": {},
   "source": [
    "On average, the answer only makes up for about `6%` of the question.  This isn't a huge number, and means that we probably can't just hope that hearing a question will enable us to figure out the answer.  We'll probably have to study.\n",
    "\n",
    "## Recycled Questions\n",
    "\n",
    "We want to investigate how often new questions are repeats of older ones.\n",
    "\n",
    "To do this, we can:\n",
    "\n",
    "- Sort `jeopardy` in order of ascending air date\n",
    "- Maintain a set called `terms_used` that will be empty initially\n",
    "- Iterate through each row of `jeopardy`\n",
    "- Split `clean_question` into words, remove any word shorter than `6` characters, and check if each word occurs in `terms_used`\n",
    "\n",
    "This allows us to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables us to filter out words like `the` and `than`, which are commonly used, but don't tell you a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53692053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722104187855287"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split()\n",
    "        split_question = [q for q in split_question if len(q) > 5]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a003462",
   "metadata": {},
   "source": [
    "There is about `87%` overlap between terms in new questions and terms in old questions. However, this doesn't look at phrases, it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions.\n",
    "\n",
    "## Low Value vs High Value Questions\n",
    "\n",
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money when we're on Jeopardy. \n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions using a chi-squared test. We'll first need to narrow down the questions into two categories:\n",
    "\n",
    "- Low value - Any row where `Value` is less than `800`\n",
    "- High value - Any row where `Value` is greater than `800`\n",
    "\n",
    "We'll then be able to loop through each of the terms from the last screen, `terms_used`, and:\n",
    "\n",
    "- Find the number of low value questions the word occurs in\n",
    "- Find the number of high value questions the word occurs in\n",
    "- Find the percentage of questions the word occurs in\n",
    "- Based on the percentage of questions the word occurs in, find expected counts\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab9d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify values\n",
    "def classify_value(row):\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d755d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] = jeopardy.apply(classify_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d8da9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counting terms in low and high values\n",
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split():\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e3055",
   "metadata": {},
   "source": [
    "Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5c9aefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (10, 10),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (9, 25),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5200eba",
   "metadata": {},
   "source": [
    "## Applying the Chi-Squared Test\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute the expected counts and the chi-squared value. The significance level will be a p-value less than 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4768e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=4.6338644448358, pvalue=0.03134688230199346),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.05693531027303224, pvalue=0.8114070706676093),\n",
       " Power_divergenceResult(statistic=0.46338644448358013, pvalue=0.49604555208958945),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e8a2357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bologna'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_terms[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69c2c7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61422"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a45fb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155508"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_value_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a4b0b",
   "metadata": {},
   "source": [
    "We notice that one term `bologna` has a significant difference (p-value is lower 0.05) in usage between high value and low value rows. It appears in high values more often.\n",
    "\n",
    "## Conclusion \n",
    "\n",
    "We've explored the Jeopardy questions data set and found out that:\n",
    "\n",
    "- The question contains in average about `6%` of the answer words. It is low value.\n",
    "\n",
    "\n",
    "- There is about `87%` overlap between terms in new questions and terms in old questions. However, this doesn't look at phrases, it looks at single terms.\n",
    "\n",
    "\n",
    "- There Are terms that occur more often in a certain category - for example, the term `'bologna'` is more characteristic of the `High value` category. We can prepare better if we pay more attention to some specific words, themes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
